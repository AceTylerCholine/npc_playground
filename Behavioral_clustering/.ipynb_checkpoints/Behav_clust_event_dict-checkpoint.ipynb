{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6cc5b8-148d-47fa-a2df-a23a690a43c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T22:14:37.106340Z",
     "iopub.status.busy": "2024-07-23T22:14:37.106340Z",
     "iopub.status.idle": "2024-07-23T22:14:44.465176Z",
     "shell.execute_reply": "2024-07-23T22:14:44.463169Z",
     "shell.execute_reply.started": "2024-07-23T22:14:37.106340Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import multirecording_spikeanalysis as spike\n",
    "from scipy.stats import chi2_contingency\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c629b68-3bd3-4dd3-8350-56459434f46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T22:14:44.470183Z",
     "iopub.status.busy": "2024-07-23T22:14:44.468179Z",
     "iopub.status.idle": "2024-07-23T22:14:44.560531Z",
     "shell.execute_reply": "2024-07-23T22:14:44.558533Z",
     "shell.execute_reply.started": "2024-07-23T22:14:44.470183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the DataFrame using pandas\n",
    "rce3_alone_clusters = pd.read_pickle(\"rce_pilot_3_alone_comp_cluster_ranges.pkl\")\n",
    "\n",
    "# Initialize the dictionary\n",
    "timestamp_dicts = {}\n",
    "\n",
    "# Loop through each row of the DataFrame to populate the dictionary\n",
    "for index, row in rce3_alone_clusters.iterrows():\n",
    "    # Define the key as a combination of session_dir and current_subject\n",
    "    key = f\"{row['session_dir']}\"\n",
    "\n",
    "    start_pos = key.find('subj_')\n",
    "    # Add the length of 'subj_' and 3 additional characters to include after 'subj_'\n",
    "    end_pos = start_pos + len('subj_') + 3\n",
    "    # Slice the recording key to get everything up to and including the subject identifier plus three characters\n",
    "    key_without_suffix = key[:end_pos]\n",
    "    \n",
    "    # Initialize nested dictionary for this key if not already present\n",
    "    if key not in timestamp_dicts:\n",
    "        timestamp_dicts[key_without_suffix] = {}\n",
    "\n",
    "    # Loop through the cluster_timestamps_ranges_dict to populate conditions\n",
    "    for condition, ranges in row['cluster_timestamps_ranges_dict'].items():\n",
    "        # Check if the condition key already exists, if not initialize a list\n",
    "        if condition not in timestamp_dicts[key_without_suffix]:\n",
    "            timestamp_dicts[key_without_suffix][str(condition)] = []\n",
    "\n",
    "        # Extend the existing list with new ranges\n",
    "        modified_ranges = [(start // 20, end // 20) for start, end in ranges]\n",
    "        timestamp_dicts[key_without_suffix][str(condition)].extend(modified_ranges)\n",
    "\n",
    "# Optionally, convert the lists to numpy arrays as in your previous code\n",
    "for subj_recording in timestamp_dicts:\n",
    "    for condition in timestamp_dicts[subj_recording]:\n",
    "        timestamp_dicts[subj_recording][condition] = np.array(timestamp_dicts[subj_recording][condition], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee1c3b7-3d6e-4caa-8e06-2399f4ccd046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T22:14:50.796102Z",
     "iopub.status.busy": "2024-07-23T22:14:50.796102Z",
     "iopub.status.idle": "2024-07-23T22:14:50.833101Z",
     "shell.execute_reply": "2024-07-23T22:14:50.831097Z",
     "shell.execute_reply.started": "2024-07-23T22:14:50.796102Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_intervals(ranges):\n",
    "    \"\"\"Combine intervals that are within 250 milliseconds of each other.\"\"\"\n",
    "    if ranges.size == 0:\n",
    "        return ranges\n",
    "    # Sort ranges based on the start times\n",
    "    sorted_ranges = np.array(sorted(ranges, key=lambda x: x[0]))\n",
    "    combined = [sorted_ranges[0]]\n",
    "\n",
    "    for current in sorted_ranges[1:]:\n",
    "        last = combined[-1]\n",
    "        # If the current start is within 250 ms of the last end, combine them\n",
    "        if current[0] - last[1] <= 250:\n",
    "            combined[-1] = [last[0], max(last[1], current[1])]\n",
    "        else:\n",
    "            combined.append(current)\n",
    "\n",
    "    return np.array(combined)\n",
    "\n",
    "def remove_short_intervals(ranges):\n",
    "    \"\"\"Remove intervals that are less than 250 milliseconds long.\"\"\"\n",
    "    return np.array([interval for interval in ranges if interval[1] - interval[0] >= 250])\n",
    "\n",
    "def process_timestamps_nested(timestamp_dicts):\n",
    "    timestamp_dicts_cut = {}\n",
    "    for date_key, clusters in timestamp_dicts.items():\n",
    "        timestamp_dicts_cut[date_key] = {}\n",
    "        for cluster_key, intervals in clusters.items():\n",
    "            intervals = np.array(intervals)  # Ensure intervals is a numpy array\n",
    "            if intervals.size > 0 and intervals.ndim == 2:  # Check if there are any intervals and it's 2-dimensional\n",
    "                combined = combine_intervals(intervals)\n",
    "                cleaned = remove_short_intervals(combined)\n",
    "                timestamp_dicts_cut[date_key][cluster_key] = cleaned\n",
    "            else:\n",
    "                timestamp_dicts_cut[date_key][cluster_key] = np.array([])  # Handle empty or malformed input case\n",
    "    return timestamp_dicts_cut\n",
    "\n",
    "# Assuming timestamp_dicts is defined and filled with your data\n",
    "timestamp_dicts_cut = process_timestamps_nested(timestamp_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74cc2a80-af82-4475-829f-4ad328eee86c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T22:22:06.646589Z",
     "iopub.status.busy": "2024-07-23T22:22:06.645599Z",
     "iopub.status.idle": "2024-07-23T22:22:06.668588Z",
     "shell.execute_reply": "2024-07-23T22:22:06.666600Z",
     "shell.execute_reply.started": "2024-07-23T22:22:06.646589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the structure for the event dictionary based on clusters\n",
    "event_dicts = {}\n",
    "\n",
    "# Loop through each session directory and subject\n",
    "for session_dir, clusters in timestamp_dicts_cut.items():\n",
    "    # Initialize the dictionary for this session if it's not already present\n",
    "    if session_dir not in event_dicts:\n",
    "        event_dicts[session_dir] = {}\n",
    "\n",
    "    # Populate the dictionary with clusters as events\n",
    "    for cluster_id, intervals in clusters.items():\n",
    "        # Initialize the cluster as an event key if not present\n",
    "        if cluster_id not in event_dicts[session_dir]:\n",
    "            event_dicts[session_dir][cluster_id] = []\n",
    "\n",
    "        # Directly assign the time intervals to the cluster\n",
    "        event_dicts[session_dir][cluster_id] = intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9ca01-b4bc-4644-b755-a14699a7f8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
