{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e280a2d6-49cc-4184-b64c-cd1f1f373bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T18:18:48.479611Z",
     "iopub.status.busy": "2024-07-31T18:18:48.476621Z",
     "iopub.status.idle": "2024-07-31T18:19:00.329569Z",
     "shell.execute_reply": "2024-07-31T18:19:00.325560Z",
     "shell.execute_reply.started": "2024-07-31T18:18:48.479611Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'multirecording_spikeanalysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultirecording_spikeanalysis\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mspike\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'multirecording_spikeanalysis'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import multirecording_spikeanalysis as spike\n",
    "from scipy.stats import chi2_contingency\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb269-1242-4144-bb26-d0712052030f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.330566Z",
     "iopub.status.idle": "2024-07-31T18:19:00.331565Z",
     "shell.execute_reply": "2024-07-31T18:19:00.330566Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.330566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the DataFrame using pandas\n",
    "rce3_alone_clusters = pd.read_pickle(\"rce_pilot_3_alone_comp_cluster_ranges.pkl\")\n",
    "\n",
    "# Initialize the dictionary\n",
    "timestamp_dicts = {}\n",
    "\n",
    "# Loop through each row of the DataFrame to populate the dictionary\n",
    "for index, row in rce3_alone_clusters.iterrows():\n",
    "    # Define the key as a combination of session_dir and current_subject\n",
    "    key = f\"{row['session_dir']}\"\n",
    "\n",
    "    start_pos = key.find('subj_')\n",
    "    # Add the length of 'subj_' and 3 additional characters to include after 'subj_'\n",
    "    end_pos = start_pos + len('subj_') + 3\n",
    "    # Slice the recording key to get everything up to and including the subject identifier plus three characters\n",
    "    key_without_suffix = key[:end_pos]\n",
    "    \n",
    "    # Initialize nested dictionary for this key if not already present\n",
    "    if key not in timestamp_dicts:\n",
    "        timestamp_dicts[key_without_suffix] = {}\n",
    "\n",
    "    # Loop through the cluster_timestamps_ranges_dict to populate conditions\n",
    "    for condition, ranges in row['cluster_timestamps_ranges_dict'].items():\n",
    "        # Check if the condition key already exists, if not initialize a list\n",
    "        if condition not in timestamp_dicts[key_without_suffix]:\n",
    "            timestamp_dicts[key_without_suffix][str(condition)] = []\n",
    "\n",
    "        # Extend the existing list with new ranges\n",
    "        modified_ranges = [(start // 20, end // 20) for start, end in ranges]\n",
    "        timestamp_dicts[key_without_suffix][str(condition)].extend(modified_ranges)\n",
    "\n",
    "# Optionally, convert the lists to numpy arrays as in your previous code\n",
    "for subj_recording in timestamp_dicts:\n",
    "    for condition in timestamp_dicts[subj_recording]:\n",
    "        timestamp_dicts[subj_recording][condition] = np.array(timestamp_dicts[subj_recording][condition], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379c2ed-8917-4835-b714-db59ba5a7767",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.334576Z",
     "iopub.status.idle": "2024-07-31T18:19:00.335568Z",
     "shell.execute_reply": "2024-07-31T18:19:00.335568Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.335568Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_intervals(ranges):\n",
    "    \"\"\"Combine intervals that are within 250 milliseconds of each other.\"\"\"\n",
    "    if ranges.size == 0:\n",
    "        return ranges\n",
    "    # Sort ranges based on the start times\n",
    "    sorted_ranges = np.array(sorted(ranges, key=lambda x: x[0]))\n",
    "    combined = [sorted_ranges[0]]\n",
    "\n",
    "    for current in sorted_ranges[1:]:\n",
    "        last = combined[-1]\n",
    "        # If the current start is within 250 ms of the last end, combine them\n",
    "        if current[0] - last[1] <= 250:\n",
    "            combined[-1] = [last[0], max(last[1], current[1])]\n",
    "        else:\n",
    "            combined.append(current)\n",
    "\n",
    "    return np.array(combined)\n",
    "\n",
    "def remove_short_intervals(ranges):\n",
    "    \"\"\"Remove intervals that are less than 250 milliseconds long.\"\"\"\n",
    "    return np.array([interval for interval in ranges if interval[1] - interval[0] >= 250])\n",
    "\n",
    "def process_timestamps_nested(timestamp_dicts):\n",
    "    timestamp_dicts_cut = {}\n",
    "    for date_key, clusters in timestamp_dicts.items():\n",
    "        timestamp_dicts_cut[date_key] = {}\n",
    "        for cluster_key, intervals in clusters.items():\n",
    "            intervals = np.array(intervals)  # Ensure intervals is a numpy array\n",
    "            if intervals.size > 0 and intervals.ndim == 2:  # Check if there are any intervals and it's 2-dimensional\n",
    "                combined = combine_intervals(intervals)\n",
    "                cleaned = remove_short_intervals(combined)\n",
    "                timestamp_dicts_cut[date_key][cluster_key] = cleaned\n",
    "            else:\n",
    "                timestamp_dicts_cut[date_key][cluster_key] = np.array([])  # Handle empty or malformed input case\n",
    "    return timestamp_dicts_cut\n",
    "\n",
    "# Assuming timestamp_dicts is defined and filled with your data\n",
    "timestamp_dicts_cut = process_timestamps_nested(timestamp_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af830256-9196-4d5a-a3a5-d2eb3234f696",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.337569Z",
     "iopub.status.idle": "2024-07-31T18:19:00.339573Z",
     "shell.execute_reply": "2024-07-31T18:19:00.338572Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.338572Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_next_window(start_time, all_timestamps, all_ranges, gap):\n",
    "    # Find the next start time that is greater than the given start_time\n",
    "    next_start = min([t for t in all_timestamps if t > start_time], default=None)\n",
    "    if next_start is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Determine the maximum end time that doesn't exceed next_start + gap\n",
    "    potential_ends = [end for start, end in all_ranges if start >= next_start and end <= next_start + gap]\n",
    "    if not potential_ends:\n",
    "        return next_start, next_start + gap  # Extend to the full window length if no end within range\n",
    "    next_end = max(potential_ends)\n",
    "    return next_start, next_end\n",
    "\n",
    "# Process each recording in timestamp_dicts_cut\n",
    "windowed_events = {}\n",
    "\n",
    "for recording_key, clusters in timestamp_dicts_cut.items():\n",
    "    # Prepare data arrays\n",
    "    all_ranges = []\n",
    "    all_cluster_ids = []\n",
    "    for cluster_id, times in clusters.items():\n",
    "        for start_end in times:\n",
    "            all_ranges.append(start_end)\n",
    "            all_cluster_ids.append(cluster_id)\n",
    "    \n",
    "    all_starts = np.array([r[0] for r in all_ranges])\n",
    "    all_ends = np.array([r[1] for r in all_ranges])\n",
    "    \n",
    "    # Sort ranges by start times for processing order\n",
    "    sorted_indices = np.argsort(all_starts)\n",
    "    all_starts = all_starts[sorted_indices]\n",
    "    all_ends = all_ends[sorted_indices]\n",
    "    all_cluster_ids = [all_cluster_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    # Initialize windows\n",
    "    min_timestamp = all_starts.min()\n",
    "    dynamic_windows = [(min_timestamp, min(min_timestamp + 30000, all_ends.max()))]\n",
    "    \n",
    "    # Find subsequent windows\n",
    "    current_end = dynamic_windows[-1][1]\n",
    "    while True:\n",
    "        next_start, next_end = find_next_window(current_end, all_starts, list(zip(all_starts, all_ends)), 30100)\n",
    "        if next_start is None:\n",
    "            break\n",
    "        dynamic_windows.append((next_start, next_end))\n",
    "        current_end = next_end\n",
    "\n",
    "    # Map clusters to windows\n",
    "    windows_dict = {}\n",
    "    for window_num, (window_start, window_end) in enumerate(dynamic_windows):\n",
    "        clusters_in_window = []\n",
    "        for idx, (start, end) in enumerate(zip(all_starts, all_ends)):\n",
    "            if start >= window_start and end <= window_end and all_cluster_ids[idx] != '4':  # The last and statement removes cluster '4' because only 1 occurs so far\n",
    "                clusters_in_window.append(all_cluster_ids[idx])\n",
    "        \n",
    "        if clusters_in_window:  # Only store windows with data\n",
    "            windows_dict[f\"Window {window_num + 1}\"] = clusters_in_window\n",
    "\n",
    "    windowed_events[recording_key] = windows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d2810-0043-46e5-8cf7-9fa9c7b41074",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.341573Z",
     "iopub.status.idle": "2024-07-31T18:19:00.342568Z",
     "shell.execute_reply": "2024-07-31T18:19:00.341573Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.341573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assume timestamp_dicts_cut is already defined and loaded with data\n",
    "timestamps = timestamp_dicts_cut['20240320_171038_alone_comp_subj_4-2']\n",
    "\n",
    "# Initialize an empty list to collect all timestamp pairs\n",
    "all_timestamps = []\n",
    "\n",
    "# Iterate over each key in the dictionary and extend the list with the arrays\n",
    "for key in timestamps.keys():\n",
    "    all_timestamps.extend(timestamps[key])\n",
    "\n",
    "# Sort all timestamp pairs based on the first element of each pair\n",
    "all_timestamps_sorted = sorted(all_timestamps, key=lambda x: x[0])\n",
    "\n",
    "# Convert the sorted list of pairs into a numpy array\n",
    "combined_sorted_array = np.array(all_timestamps_sorted)\n",
    "\n",
    "# Now combined_sorted_array is a single long array of all sorted timestamps\n",
    "print(combined_sorted_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e226435-f21b-41ec-9829-bb985c0d7c60",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.344567Z",
     "iopub.status.idle": "2024-07-31T18:19:00.345569Z",
     "shell.execute_reply": "2024-07-31T18:19:00.344567Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.344567Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_sorted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67564e18-e212-4ba4-a987-ad692ee7b54c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.348569Z",
     "iopub.status.idle": "2024-07-31T18:19:00.349567Z",
     "shell.execute_reply": "2024-07-31T18:19:00.349567Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.349567Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_sorted_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17825ea-74a1-47c6-9107-bf607e2fe88b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.352568Z",
     "iopub.status.idle": "2024-07-31T18:19:00.353567Z",
     "shell.execute_reply": "2024-07-31T18:19:00.353567Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.353567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to collect the differences\n",
    "differences = []\n",
    "\n",
    "# Iterate through the array of pairs to calculate the differences\n",
    "for i in range(len(combined_sorted_array) - 1):\n",
    "    current_end = combined_sorted_array[i][1]\n",
    "    next_start = combined_sorted_array[i + 1][0]\n",
    "    difference = next_start - current_end\n",
    "\n",
    "    # Only include differences less than 29,000\n",
    "    if difference < 30100:\n",
    "        differences.append(difference)\n",
    "\n",
    "# Convert the list of valid differences into a numpy array\n",
    "valid_differences_array = np.array(differences)\n",
    "\n",
    "# Now valid_differences_array contains the required differences\n",
    "print(valid_differences_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a6921-19f7-4f87-b37e-654f8147caa5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.356569Z",
     "iopub.status.idle": "2024-07-31T18:19:00.357569Z",
     "shell.execute_reply": "2024-07-31T18:19:00.357569Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.357569Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_next_window(start_time, all_timestamps, all_ranges, gap):\n",
    "    # Debugging addition: Output the current start time and the computation of the next start\n",
    "    print(f\"Finding next window from start time: {start_time}\")\n",
    "    next_starts = [t for t in all_timestamps if t > start_time]\n",
    "    if not next_starts:\n",
    "        print(\"No more starts found.\")\n",
    "        return None, None\n",
    "    \n",
    "    next_start = min(next_starts)\n",
    "    print(f\"Next start found at: {next_start}\")\n",
    "    \n",
    "    # Determine the maximum end time that doesn't exceed next_start + gap\n",
    "    potential_ends = [end for start, end in all_ranges if start >= next_start and end <= next_start + gap]\n",
    "    if not potential_ends:\n",
    "        print(\"No ends found within the window range, using default window length.\")\n",
    "        return next_start, next_start + gap\n",
    "    \n",
    "    next_end = max(potential_ends)\n",
    "    print(f\"Next end within window range found at: {next_end}\")\n",
    "    return next_start, next_end\n",
    "\n",
    "# The rest of the script for processing would follow here, ensuring all debug outputs\n",
    "# help trace the steps and values correctly.\n",
    "\n",
    "# Process each recording in timestamp_dicts_cut\n",
    "windowed_events = {}\n",
    "\n",
    "for recording_key, clusters in timestamp_dicts_cut.items():\n",
    "    # Prepare data arrays\n",
    "    all_ranges = []\n",
    "    all_cluster_ids = []\n",
    "    for cluster_id, times in clusters.items():\n",
    "        for start_end in times:\n",
    "            all_ranges.append(start_end)\n",
    "            all_cluster_ids.append(cluster_id)\n",
    "    \n",
    "    all_starts = np.array([r[0] for r in all_ranges])\n",
    "    all_ends = np.array([r[1] for r in all_ranges])\n",
    "    \n",
    "    # Sort ranges by start times for processing order\n",
    "    sorted_indices = np.argsort(all_starts)\n",
    "    all_starts = all_starts[sorted_indices]\n",
    "    all_ends = all_ends[sorted_indices]\n",
    "    all_cluster_ids = [all_cluster_ids[i] for i in sorted_indices]\n",
    "    \n",
    "    # Initialize windows\n",
    "    min_timestamp = all_starts.min()\n",
    "    dynamic_windows = [(min_timestamp, min(min_timestamp + 30000, all_ends.max()))]\n",
    "    \n",
    "    # Find subsequent windows\n",
    "    current_end = dynamic_windows[-1][1]\n",
    "    while True:\n",
    "        next_start, next_end = find_next_window(current_end, all_starts, list(zip(all_starts, all_ends)), 30100)\n",
    "        if next_start is None:\n",
    "            break\n",
    "        dynamic_windows.append((next_start, next_end))\n",
    "        current_end = next_end\n",
    "\n",
    "    # Map clusters to windows\n",
    "    windows_dict = {}\n",
    "    for window_num, (window_start, window_end) in enumerate(dynamic_windows):\n",
    "        clusters_in_window = []\n",
    "        for idx, (start, end) in enumerate(zip(all_starts, all_ends)):\n",
    "            if start >= window_start and end <= window_end and all_cluster_ids[idx] != '4':  # The last and statement removes cluster '4' because only 1 occurs so far\n",
    "                clusters_in_window.append(all_cluster_ids[idx])\n",
    "        \n",
    "        if clusters_in_window:  # Only store windows with data\n",
    "            windows_dict[f\"Window {window_num + 1}\"] = clusters_in_window\n",
    "\n",
    "    windowed_events[recording_key] = windows_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003a64f-155d-43ae-a805-917c96669e2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.360568Z",
     "iopub.status.idle": "2024-07-31T18:19:00.361566Z",
     "shell.execute_reply": "2024-07-31T18:19:00.361566Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.361566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to collect the differences\n",
    "differences = []\n",
    "\n",
    "# Iterate through the array of pairs to calculate the differences\n",
    "for i in range(len(combined_sorted_array) - 1):\n",
    "    current_end = combined_sorted_array[i][1]\n",
    "    next_start = combined_sorted_array[i + 1][0]\n",
    "    difference = next_start - current_end\n",
    "\n",
    "    differences.append(difference)\n",
    "\n",
    "# Convert the list of valid differences into a numpy array\n",
    "valid_differences_array = np.array(differences)\n",
    "\n",
    "# Now valid_differences_array contains the required differences\n",
    "valid_differences_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb6ee6-fe7c-440a-a6a8-9c39c7862a2b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.364571Z",
     "iopub.status.idle": "2024-07-31T18:19:00.365573Z",
     "shell.execute_reply": "2024-07-31T18:19:00.364571Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.364571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to collect the window lengths\n",
    "window_lengths = []\n",
    "\n",
    "# Iterate through the dynamic_windows list to calculate lengths\n",
    "for start_time, end_time in dynamic_windows:\n",
    "    window_length = end_time - start_time\n",
    "    window_lengths.append(window_length)\n",
    "\n",
    "# Print the window lengths\n",
    "print(window_lengths)\n",
    "\n",
    "# Convert the list of lengths into a numpy array if needed for further analysis\n",
    "window_lengths_array = np.array(window_lengths)\n",
    "print(window_lengths_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95224fec-ef18-4859-ba0e-9eb2cd402d3d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-31T18:19:00.367566Z",
     "iopub.status.idle": "2024-07-31T18:19:00.369572Z",
     "shell.execute_reply": "2024-07-31T18:19:00.368567Z",
     "shell.execute_reply.started": "2024-07-31T18:19:00.368567Z"
    }
   },
   "outputs": [],
   "source": [
    "dynamic_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602920b-4eec-4739-b940-6e4b7ccef545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
