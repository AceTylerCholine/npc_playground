{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1b795c-495e-49bb-8714-01a18850ac9b",
   "metadata": {},
   "source": [
    "# EPhys Data Analysis Tutorial\n",
    "\n",
    "This tutorial demonstrates a step-by-step approach to processing electrophysiology (EPhys) data for analysis using Meghan's multirecording_spikeanalysis script, the RCE Pilot 2 behavior spreadsheet, and directories of phy folders (with spike_times.npy, spike_clusters.npy, & cluster_group.tsv) for each ephys recording.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Import all the libraries you'll be using, including Meghan's multirecording_spikeanalysis.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81770ad7-1919-4116-b994-5cdc0d77da9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import multirecording_spikeanalysis as spike"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695e1cb-5bf4-4fe2-979b-f1f2cb4fb677",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "First, we load the relevant EPhys data from the RCE Pilot 2 spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4875ae34-edf9-45e8-a7e0-49a1661231b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['condition ', 'session_dir', 'all_subjects', 'tone_start_timestamp', 'tone_stop_timestamp']\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_excel('rce_pilot_2_per_video_trial_labels.xlsx', usecols=cols, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aac8f4-0a3d-4b6c-8d6b-737ad89a1c5b",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Next, we rearrange the spreadsheet in order for it to prepare it for ephys recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc1b799-5a71-43ea-8f9e-f38cce47dd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = df.dropna() # Drop the rows missing data\n",
    "df3 = df2.copy()\n",
    "df3['all_subjects'] = df3['all_subjects'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x) # Make the 'all_subjects' column readable as a list\n",
    "df4 = df3[df3['all_subjects'].apply(lambda x: len(x) < 3)] # Ignore novel sessions for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f0136-d2f4-42bc-bd55-a01367e569de",
   "metadata": {},
   "source": [
    "## Data Structuring\n",
    "We'll structure the data into a new DataFrame that aligns with our analysis goals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112f9507-69df-4874-8db4-2dda8571c338",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to collect data for the new DataFrame\n",
    "new_df_data = []\n",
    "\n",
    "for _, row in df4.iterrows():\n",
    "    session_dir = row['session_dir']\n",
    "    subjects = row['all_subjects']\n",
    "    condition = row['condition ']\n",
    "\n",
    "    # Split session_dir on '_subj_' and take the first part only\n",
    "    # This ensures everything after '_subj_' is ignored\n",
    "    base_session_dir = session_dir.split('_subj_')[0]\n",
    "\n",
    "    for subject in subjects:\n",
    "        subject_formatted = subject.replace('.', '-')\n",
    "        # Append formatted subject to the base session_dir correctly\n",
    "        subj_recording = f\"{base_session_dir}_subj_{subject_formatted}\"\n",
    "        new_df_data.append({\n",
    "            'session_dir': session_dir,\n",
    "            'subject': subject,\n",
    "            'subj_recording': subj_recording,\n",
    "            'condition': condition if condition in ['rewarded', 'omission', 'both_rewarded', 'tie'] else ('win' if str(condition) == str(subject) else 'lose'),\n",
    "            'tone_start_timestamp': row['tone_start_timestamp'],\n",
    "            'tone_stop_timestamp': row['tone_stop_timestamp']\n",
    "        })\n",
    "\n",
    "# Convert list to DataFrame\n",
    "new_df = pd.DataFrame(new_df_data)\n",
    "new_df = new_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe64e4-6bad-4d03-b01a-1471e5710258",
   "metadata": {},
   "source": [
    "## Timestamp Dictionary Preparation\n",
    "Prepare dictionaries of event timestamps to match with the ephys recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5284a66-5274-4f20-a0f2-82e64e122a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare timestamp_dicts from new_df\n",
    "timestamp_dicts = {}\n",
    "for _, row in new_df.iterrows():\n",
    "    key = row['subj_recording']\n",
    "    condition = row['condition']\n",
    "    timestamp_start = int(row['tone_start_timestamp']) // 20\n",
    "    timestamp_end = int(row['tone_stop_timestamp']) // 20\n",
    "    tuple_val = (timestamp_start, timestamp_end)\n",
    "\n",
    "    if key not in timestamp_dicts:\n",
    "        timestamp_dicts[key] = {cond: [] for cond in ['rewarded', 'win', 'lose', 'omission', 'both_rewarded', 'tie']}\n",
    "    timestamp_dicts[key][condition].append(tuple_val)\n",
    "\n",
    "# Convert lists in timestamp_dicts to numpy arrays\n",
    "for subj_recording in timestamp_dicts:\n",
    "    for condition in timestamp_dicts[subj_recording]:\n",
    "        timestamp_dicts[subj_recording][condition] = np.array(timestamp_dicts[subj_recording][condition], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537d178-124d-4cd2-921d-d6de5d3f254c",
   "metadata": {},
   "source": [
    "## EPhys Recording Collection\n",
    "Load EPhys recordings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b94ceca-39f0-4933-a018-a5858d86bf27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1-4_t4b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 96 is unsorted & has 5811 spikes\n",
      "Unit 96 will be deleted\n",
      "Unit 95 is unsorted & has 6458 spikes\n",
      "Unit 95 will be deleted\n",
      "20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-4_t3b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230621_111240_standard_comp_to_omission_D5_subj_1-4_t3b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230624_105855_standard_comp_to_both_rewarded_D3_subj_1-2_t1b2L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230619_115321_standard_comp_to_omission_D3_subj_1-4_t3b3L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230625_112913_standard_comp_to_both_rewarded_D4_subj_1-1_t1b2L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 92 is unsorted & has 2494 spikes\n",
      "Unit 92 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 103 is unsorted & has 512 spikes\n",
      "Unit 103 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-2_t3b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230618_100636_standard_comp_to_omission_D2_subj_1-1_t1b2L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230624_105855_standard_comp_to_both_rewarded_D3_subj_1-4_t3b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "20230620_114347_standard_comp_to_omission_D4_subj_1-1_t1b2L_box_2_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "# Construct the path in a platform-independent way (HiPerGator or Windows)\n",
    "ephys_path = Path('.') / 'export' / 'updated_phys' / 'non-novel' / 'all_non_novel'\n",
    "\n",
    "ephys_data = spike.EphysRecordingCollection(str(ephys_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab04be-9f97-41d5-86b8-7f33318c00bf",
   "metadata": {},
   "source": [
    "## Assign Dictionaries to Collection\n",
    "Create dictionaries for each recording, and assign it and the subject number to the recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac0dc2f-c4d9-4601-8dec-cd65d6be3ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for recording in ephys_data.collection.keys():\n",
    "    # Check if the recording key (without everything after subject #) is in timestamp_dicts\n",
    "    start_pos = recording.find('subj_')\n",
    "    # Add the length of 'subj_' and 3 additional characters to include after 'subj_'\n",
    "    end_pos = start_pos + len('subj_') + 3\n",
    "    # Slice the recording key to get everything up to and including the subject identifier plus three characters\n",
    "    recording_key_without_suffix = recording[:end_pos]\n",
    "    if recording_key_without_suffix in timestamp_dicts:\n",
    "        # Assign the corresponding timestamp_dicts dictionary to event_dict\n",
    "        ephys_data.collection[recording].event_dict = timestamp_dicts[recording_key_without_suffix]\n",
    "        \n",
    "        # Extract the subject from the recording key\n",
    "        start = recording.find('subj_') + 5  # Start index after 'subj_'\n",
    "        subject = recording[start:start+3]\n",
    "        \n",
    "        # Assign the extracted subject\n",
    "        ephys_data.collection[recording].subject = subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c7ec2-0c00-47f5-a307-cd5fb186ae4c",
   "metadata": {},
   "source": [
    "### (Optional) Save the ephys_data for later use:\n",
    "If you don't, you'll have to redo the previous steps each time you want to do an analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7526e496-0356-455e-9a17-1eb0dd43c9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pickle.dump(ephys_data, open(\"ephys_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92d51a-2a5e-4054-866d-755f39d2e4f0",
   "metadata": {},
   "source": [
    "### To import the pickle you can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ae733a-5a6c-4639-ac4b-2db9ff93b286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ephys_data = pickle.load(open('ephys_data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fcd94a-f15b-4adf-bc19-5e6350d395df",
   "metadata": {},
   "source": [
    "## Analysis Initialization\n",
    "Finally, initialize the spike analysis with the organized EPhys data (it would be nice to pickle this, but even with 4 CPUs & 64 GB RAM, it still crashed trying to pickle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424fd1a7-c983-40dd-ba22-5c5d65dc994b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "spike_analysis = spike.SpikeAnalysis_MultiRecording(ephys_data, timebin = 5, smoothing_window=250, ignore_freq = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c385d46-ecc2-4425-96c5-6bab72f8a980",
   "metadata": {},
   "source": [
    "### Now you can do functions like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee74e82-2774-426d-bec4-77f347b5a5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the collection dictionary\n",
    "recordings = spike_analysis.ephyscollection.collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90fe68a1-a03a-4cd7-a031-7f8068ea9173",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 20230618_100636_standard_comp_to_omission_D2_subj_1-4_t4b3L_box1_merged.rec successfully retrieved.\n"
     ]
    }
   ],
   "source": [
    "recording_name = '20230618_100636_standard_comp_to_omission_D2_subj_1-4_t4b3L_box1_merged.rec'\n",
    "recording1 = recordings.get(recording_name)\n",
    "\n",
    "if recording1 is None:\n",
    "    print(f\"Recording named {recording_name} not found.\")\n",
    "else:\n",
    "    print(f\"Recording {recording_name} successfully retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "986f374f-38c3-4cdb-8884-05ce39238e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'event_dict', 'freq_dict', 'get_spike_specs', 'get_unit_labels', 'get_unit_timestamps', 'labels_dict', 'path', 'sampling_rate', 'spiketrain', 'subject', 'timestamps_var', 'unit_array', 'unit_firing_rate_array', 'unit_firing_rates', 'unit_spiketrains', 'unit_timestamps', 'wilcox_dfs', 'zscored_events']\n"
     ]
    }
   ],
   "source": [
    "if recording1:\n",
    "    # Example of accessing an attribute or method of the recording\n",
    "    print(dir(recording1))  # Lists all methods and attributes of the recording\n",
    "    # If there are specific operations you need to perform, do them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e96b8c1-3b45-4945-b0eb-c4b73f1bb434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  54962,   64962],\n",
       "       [ 379962,  389962],\n",
       "       [ 484962,  494962],\n",
       "       [ 579962,  589962],\n",
       "       [ 654962,  664962],\n",
       "       [1554961, 1564961]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.event_dict['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43d4fb1b-054c-4fd9-811f-8e182cf09a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preevent = recording1.event_dict['win'] - 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d688f164-51c8-4671-b4f4-94c125881a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  44962,   54962],\n",
       "       [ 369962,  379962],\n",
       "       [ 474962,  484962],\n",
       "       [ 569962,  579962],\n",
       "       [ 644962,  654962],\n",
       "       [1544961, 1554961]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650dadff-dfc5-4bb2-8dd0-33f7fe8cdea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65: array([4., 4., 4., ..., 0., 0., 0.]),\n",
       " 123: array([4.8, 4.8, 4.8, ..., 0. , 0. , 0. ]),\n",
       " 103: array([8.8, 8.8, 8.8, ..., 3.2, 3.2, 3.2]),\n",
       " 83: array([2.4, 2.4, 2.4, ..., 8.8, 8.8, 8. ]),\n",
       " 118: array([1.6, 1.6, 1.6, ..., 0. , 0. , 0. ]),\n",
       " 93: array([0. , 0. , 0. , ..., 1.6, 1.6, 1.6]),\n",
       " 99: array([0. , 0. , 0. , ..., 2.4, 2.4, 2.4]),\n",
       " 105: array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 87: array([0. , 0. , 0. , ..., 1.6, 1.6, 1.6]),\n",
       " 19: array([0., 0., 0., ..., 0., 0., 0.]),\n",
       " 9: array([0., 0., 0., ..., 0., 0., 0.])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.unit_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569f9b8-925e-4db2-b876-ead35a98023e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670988"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording1.unit_firing_rates[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4ef248-d6f7-44d7-82e9-9edb7989efec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670988"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording1.unit_firing_rates[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23f22802-67d2-4c2f-a443-a8694f260901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "spike_analysis = spike.SpikeAnalysis_MultiRecording(ephys_data, timebin = 100, smoothing_window=250, ignore_freq = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70f1875a-0644-4619-8588-a8ae8153e7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recordings = spike_analysis.ephyscollection.collection\n",
    "\n",
    "recording_name = '20230618_100636_standard_comp_to_omission_D2_subj_1-4_t4b3L_box1_merged.rec'\n",
    "recording1 = recordings.get(recording_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bbd9123-4191-488f-951a-07ef6a7d6739",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14,  9,  7, ..., 11,  7,  9])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.spiketrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8760694e-a935-458f-87f2-99e134a23845",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33549"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording1.spiketrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b3ab910-632d-47ba-b0df-8b492d1b9a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65: array([2, 2, 0, ..., 0, 0, 0]),\n",
       " 123: array([2, 0, 0, ..., 0, 0, 0]),\n",
       " 103: array([2, 2, 1, ..., 1, 0, 1]),\n",
       " 83: array([0, 1, 1, ..., 1, 3, 1]),\n",
       " 118: array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 93: array([0, 0, 0, ..., 1, 0, 1]),\n",
       " 99: array([0, 0, 0, ..., 1, 1, 1]),\n",
       " 105: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 87: array([0, 0, 0, ..., 0, 1, 0]),\n",
       " 19: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 9: array([0, 0, 0, ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.unit_spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b780069e-74cc-4908-9709-b4be62b1abef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33549"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording1.unit_spiketrains[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1026e98-caf9-44f4-b5db-c63040f80edf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65: array([3.  , 3.  , 3.  , ..., 0.92, 0.92, 0.92]),\n",
       " 123: array([2.  , 2.04, 2.04, ..., 1.92, 1.92, 1.92]),\n",
       " 103: array([6.16, 6.2 , 6.24, ..., 1.68, 1.68, 1.64]),\n",
       " 83: array([3.16, 3.2 , 3.24, ..., 9.  , 8.96, 8.8 ]),\n",
       " 118: array([2.04, 2.08, 2.12, ..., 0.12, 0.12, 0.12]),\n",
       " 93: array([0.44, 0.44, 0.44, ..., 0.56, 0.56, 0.56]),\n",
       " 99: array([0.2, 0.2, 0.2, ..., 2.4, 2.4, 2.4]),\n",
       " 105: array([0.04, 0.04, 0.04, ..., 0.  , 0.  , 0.  ]),\n",
       " 87: array([0.04, 0.04, 0.04, ..., 0.84, 0.84, 0.84]),\n",
       " 19: array([0.36, 0.36, 0.36, ..., 0.08, 0.04, 0.04]),\n",
       " 9: array([0.  , 0.  , 0.  , ..., 0.96, 0.96, 0.96])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.unit_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c674554-8b73-4b5b-baff-68f5e2039862",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33549"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording1.unit_firing_rates[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e8b541e-58fe-42af-90a3-d9ac4d148df7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2686816298548392"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recording1.unit_spiketrains[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3fa021dc-9a2f-43d8-9a07-3f8f5773edbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6793370890339507"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recording1.unit_firing_rates[65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27330a2c-0384-4aea-8ba1-31125dd8e666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_firing_rate(spiketrain, smoothing_window, timebin):\n",
    "    \"\"\"\n",
    "    calculates firing rate (spikes/second)\n",
    "\n",
    "    Args (3 total, 1 required):\n",
    "        spiketrain: numpy array, in timebin (ms) bins\n",
    "        smoothing_window: int, default=250, smoothing average window (ms)\n",
    "            min smoothing_window = 1\n",
    "        timebin: int, default = 1, timebin (ms) of spiketrain\n",
    "\n",
    "    Return (1):\n",
    "        firing_rate: numpy array of firing rates in timebin sized windows\n",
    "\n",
    "    \"\"\"\n",
    "    weights = np.ones(smoothing_window) / smoothing_window * 1000 / timebin\n",
    "    firing_rate = np.convolve(spiketrain, weights, mode=\"same\")\n",
    "\n",
    "    return firing_rate\n",
    "\n",
    "fr_65_man = get_firing_rate(recording1.unit_spiketrains[65], 250, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "287b387c-27ce-482f-a11d-c37a3352e9e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.  , 3.  , 3.  , ..., 0.92, 0.92, 0.92])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_65_man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9467aa0e-723f-4ca5-8c37-42872d359aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33549"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fr_65_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "124411e1-d9ea-43fb-b758-c9c18e240f24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6793370890339507"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fr_65_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "58259649-62d0-4fba-8964-ead1e2bcf1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smoothing_window = 250\n",
    "timebin=100\n",
    "weights = np.ones(smoothing_window) / smoothing_window * 1000 / timebin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bdf142af-620d-4470-afba-3f7b4a19b938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04,\n",
       "       0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04, 0.04])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "933c3937-44f7-4d84-8dce-0dfefc3b3432",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{65: 2.6867823023312964,\n",
       " 123: 2.4372996323677625,\n",
       " 103: 8.95037707725806,\n",
       " 83: 10.921200749658166,\n",
       " 118: 1.4062834371421187,\n",
       " 106: 0.39225710116130313,\n",
       " 93: 0.8390605925296871,\n",
       " 99: 3.601850159903637,\n",
       " 105: 0.6047793755746839,\n",
       " 87: 2.4703851477392704,\n",
       " 19: 0.5144648606416482,\n",
       " 9: 1.6411607895092208}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording1.freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "05b222e1-934e-41a0-aacd-75a1236f90f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "recording_name2 = '20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged.rec'\n",
    "recording2 = recordings.get(recording_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ba9ae0fc-8d6c-4cdd-9f28-259e5de453a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{42: 12.966737226679907,\n",
       " 207: 4.308202978206947,\n",
       " 262: 2.037371013189812,\n",
       " 144: 1.7530050417911194,\n",
       " 41: 1.583321643219883,\n",
       " 162: 11.206125687711454,\n",
       " 48: 10.816731543748842,\n",
       " 45: 15.460205512925853,\n",
       " 68: 15.887047027607634,\n",
       " 259: 1.7571008479635286,\n",
       " 153: 4.2567128434680885,\n",
       " 269: 0.8229644830704971,\n",
       " 53: 2.4940534014134332,\n",
       " 168: 3.099647599762502,\n",
       " 58: 3.0358700465064166,\n",
       " 258: 2.8448299443219036,\n",
       " 14: 1.9080605611751804,\n",
       " 241: 5.830965201591923,\n",
       " 245: 0.9730465235309185,\n",
       " 28: 1.4361651785968967,\n",
       " 43: 1.4897032164219592,\n",
       " 124: 8.735476892997502,\n",
       " 221: 1.8194156133008963,\n",
       " 172: 0.4265489570980394,\n",
       " 244: 0.5236780749008851,\n",
       " 227: 0.7208618863440118,\n",
       " 226: 1.869442960121037,\n",
       " 266: 1.4376279665156142}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording2.freq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd432d44-68eb-4ac4-9ec7-9158937ac865",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{42: array([2, 1, 0, ..., 4, 2, 0]),\n",
       " 207: array([2, 1, 1, ..., 0, 3, 0]),\n",
       " 262: array([1, 0, 0, ..., 0, 0, 0]),\n",
       " 144: array([1, 1, 4, ..., 0, 0, 1]),\n",
       " 41: array([1, 0, 0, ..., 0, 0, 0]),\n",
       " 162: array([2, 1, 1, ..., 2, 1, 0]),\n",
       " 48: array([2, 0, 2, ..., 1, 0, 1]),\n",
       " 45: array([1, 1, 3, ..., 3, 3, 0]),\n",
       " 68: array([0, 1, 3, ..., 1, 0, 3]),\n",
       " 259: array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 153: array([0, 1, 0, ..., 2, 0, 0]),\n",
       " 269: array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 53: array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 168: array([0, 1, 0, ..., 0, 0, 0]),\n",
       " 58: array([0, 0, 1, ..., 0, 0, 1]),\n",
       " 258: array([0, 0, 1, ..., 0, 1, 1]),\n",
       " 14: array([0, 0, 1, ..., 0, 1, 0]),\n",
       " 241: array([0, 0, 1, ..., 0, 1, 1]),\n",
       " 245: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 28: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 43: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 124: array([0, 0, 0, ..., 1, 0, 0]),\n",
       " 221: array([0, 0, 0, ..., 0, 1, 0]),\n",
       " 244: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 227: array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 226: array([0, 0, 0, ..., 0, 1, 0]),\n",
       " 266: array([0, 0, 0, ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording2.unit_spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "917575c6-5956-46b6-a30d-0a907d0bad72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording2.freq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ae84cc38-533f-4bdf-955a-e7dd9f2e15b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recording2.unit_spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84cebb5-6483-4ff2-a9f7-19c7a8aff944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UFRC Python-3.10",
   "language": "python",
   "name": "python3-3.10-ufrc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
