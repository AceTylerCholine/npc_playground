{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe17287-bcbc-4bef-ae72-2956c90bc8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:33:46.323675Z",
     "iopub.status.busy": "2024-05-30T22:33:46.323675Z",
     "iopub.status.idle": "2024-05-30T22:34:03.657217Z",
     "shell.execute_reply": "2024-05-30T22:34:03.657217Z",
     "shell.execute_reply.started": "2024-05-30T22:33:46.323675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 92 is unsorted & has 2494 spikes\n",
      "Unit 92 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 103 is unsorted & has 512 spikes\n",
      "Unit 103 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-2_t3b3L_box1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multirecording_spikeanalysis_edit2 as spike\n",
    "\n",
    "# It takes several steps to create the timestamp_dicts, refer to Ephys_Analysis_Notebook to create\n",
    "timestamp_dicts = pickle.load(open('timestamp_dicts.pkl', 'rb'))\n",
    "\n",
    "# Construct the path in a platform-independent way (HiPerGator or Windows)\n",
    "ephys_path = Path('.') / 'export' / 'updated_phys' / 'test'\n",
    "\n",
    "ephys_data = spike.EphysRecordingCollection(str(ephys_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e513f841-140a-4e67-9613-cac28db75e36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:34:03.866040Z",
     "iopub.status.busy": "2024-05-30T22:34:03.866040Z",
     "iopub.status.idle": "2024-05-30T22:34:04.502562Z",
     "shell.execute_reply": "2024-05-30T22:34:04.502562Z",
     "shell.execute_reply.started": "2024-05-30T22:34:03.866040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "for recording in ephys_data.collection.keys():\n",
    "    # Check if the recording key (without everything after subject #) is in timestamp_dicts\n",
    "    start_pos = recording.find('subj_')\n",
    "    # Add the length of 'subj_' and 3 additional characters to include after 'subj_'\n",
    "    end_pos = start_pos + len('subj_') + 3\n",
    "    # Slice the recording key to get everything up to and including the subject identifier plus three characters\n",
    "    recording_key_without_suffix = recording[:end_pos]\n",
    "    if recording_key_without_suffix in timestamp_dicts:\n",
    "        # Assign the corresponding timestamp_dicts dictionary to event_dict\n",
    "        ephys_data.collection[recording].event_dict = timestamp_dicts[recording_key_without_suffix]\n",
    "        \n",
    "        # Extract the subject from the recording key\n",
    "        start = recording.find('subj_') + 5  # Start index after 'subj_'\n",
    "        subject = recording[start:start+3]\n",
    "        \n",
    "        # Assign the extracted subject\n",
    "        ephys_data.collection[recording].subject = subject\n",
    "        \n",
    "spike_analysis = spike.SpikeAnalysis_MultiRecording(ephys_data, timebin = 100, ignore_freq = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc223c1-2218-4f59-8969-f318088157dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:34:04.630572Z",
     "iopub.status.busy": "2024-05-30T22:34:04.630572Z",
     "iopub.status.idle": "2024-05-30T22:34:04.744070Z",
     "shell.execute_reply": "2024-05-30T22:34:04.744070Z",
     "shell.execute_reply.started": "2024-05-30T22:34:04.630572Z"
    }
   },
   "outputs": [],
   "source": [
    "event_df = spike_analysis.create_spiketrain_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58a05d6b-e37f-47e8-9c60-3b5d460f2730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:34:09.500123Z",
     "iopub.status.busy": "2024-05-30T22:34:09.500123Z",
     "iopub.status.idle": "2024-05-30T22:34:09.581957Z",
     "shell.execute_reply": "2024-05-30T22:34:09.581957Z",
     "shell.execute_reply.started": "2024-05-30T22:34:09.500123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recording</th>\n",
       "      <th>Event name</th>\n",
       "      <th>Event number</th>\n",
       "      <th>Unit number</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>bin_5</th>\n",
       "      <th>bin_6</th>\n",
       "      <th>...</th>\n",
       "      <th>bin_91</th>\n",
       "      <th>bin_92</th>\n",
       "      <th>bin_93</th>\n",
       "      <th>bin_94</th>\n",
       "      <th>bin_95</th>\n",
       "      <th>bin_96</th>\n",
       "      <th>bin_97</th>\n",
       "      <th>bin_98</th>\n",
       "      <th>bin_99</th>\n",
       "      <th>bin_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230612_101430_standard_comp_to_training_D1_s...</td>\n",
       "      <td>rewarded</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>20230622_110832_standard_comp_to_both_rewarded...</td>\n",
       "      <td>both_rewarded</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>20230622_110832_standard_comp_to_both_rewarded...</td>\n",
       "      <td>both_rewarded</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>20230622_110832_standard_comp_to_both_rewarded...</td>\n",
       "      <td>both_rewarded</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>20230622_110832_standard_comp_to_both_rewarded...</td>\n",
       "      <td>both_rewarded</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>20230622_110832_standard_comp_to_both_rewarded...</td>\n",
       "      <td>both_rewarded</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2717 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Recording     Event name  \\\n",
       "0     20230612_101430_standard_comp_to_training_D1_s...       rewarded   \n",
       "1     20230612_101430_standard_comp_to_training_D1_s...       rewarded   \n",
       "2     20230612_101430_standard_comp_to_training_D1_s...       rewarded   \n",
       "3     20230612_101430_standard_comp_to_training_D1_s...       rewarded   \n",
       "4     20230612_101430_standard_comp_to_training_D1_s...       rewarded   \n",
       "...                                                 ...            ...   \n",
       "2712  20230622_110832_standard_comp_to_both_rewarded...  both_rewarded   \n",
       "2713  20230622_110832_standard_comp_to_both_rewarded...  both_rewarded   \n",
       "2714  20230622_110832_standard_comp_to_both_rewarded...  both_rewarded   \n",
       "2715  20230622_110832_standard_comp_to_both_rewarded...  both_rewarded   \n",
       "2716  20230622_110832_standard_comp_to_both_rewarded...  both_rewarded   \n",
       "\n",
       "      Event number  Unit number  bin_1  bin_2  bin_3  bin_4  bin_5  bin_6  \\\n",
       "0                1           85    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1                2           85    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2                3           85    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3                4           85    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4                5           85    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...            ...          ...    ...    ...    ...    ...    ...    ...   \n",
       "2712            16           15    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2713            17           15    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2714            18           15    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2715            19           15    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2716            20           15    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "\n",
       "      ...  bin_91  bin_92  bin_93  bin_94  bin_95  bin_96  bin_97  bin_98  \\\n",
       "0     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3     ...     0.0     1.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4     ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "2712  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2713  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2714  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2715  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2716  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      bin_99  bin_100  \n",
       "0        0.0      NaN  \n",
       "1        0.0      NaN  \n",
       "2        0.0      NaN  \n",
       "3        0.0      NaN  \n",
       "4        0.0      NaN  \n",
       "...      ...      ...  \n",
       "2712     0.0      NaN  \n",
       "2713     0.0      0.0  \n",
       "2714     0.0      NaN  \n",
       "2715     0.0      NaN  \n",
       "2716     0.0      NaN  \n",
       "\n",
       "[2717 rows x 104 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556dc18e-e798-44df-9a94-e1044656a468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:34:47.472496Z",
     "iopub.status.busy": "2024-05-30T22:34:47.472496Z",
     "iopub.status.idle": "2024-05-30T22:34:47.492734Z",
     "shell.execute_reply": "2024-05-30T22:34:47.492734Z",
     "shell.execute_reply.started": "2024-05-30T22:34:47.472496Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_100\n",
       "0.0    33\n",
       "1.0     6\n",
       "4.0     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df['bin_100'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e86d972-6a3b-41db-92bb-81f2aad2f708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:35:05.476537Z",
     "iopub.status.busy": "2024-05-30T22:35:05.476537Z",
     "iopub.status.idle": "2024-05-30T22:35:05.494386Z",
     "shell.execute_reply": "2024-05-30T22:35:05.494386Z",
     "shell.execute_reply.started": "2024-05-30T22:35:05.476537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bin_99\n",
       "0.0    2089\n",
       "1.0     444\n",
       "2.0     100\n",
       "3.0      25\n",
       "4.0       8\n",
       "5.0       6\n",
       "6.0       4\n",
       "7.0       1\n",
       "8.0       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df['bin_99'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb41730-f893-43d0-a167-33f68ac83696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:39:19.038456Z",
     "iopub.status.busy": "2024-05-30T22:39:19.022831Z",
     "iopub.status.idle": "2024-05-30T22:39:19.279728Z",
     "shell.execute_reply": "2024-05-30T22:39:19.279728Z",
     "shell.execute_reply.started": "2024-05-30T22:39:19.038456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recording          0\n",
       "Event name         0\n",
       "Event number       0\n",
       "Unit number        0\n",
       "bin_1             39\n",
       "                ... \n",
       "bin_96            39\n",
       "bin_97            39\n",
       "bin_98            39\n",
       "bin_99            39\n",
       "bin_100         2677\n",
       "Length: 104, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4671ba20-784a-4ccd-83e2-b2da05789cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:46:07.036994Z",
     "iopub.status.busy": "2024-05-30T22:46:07.036994Z",
     "iopub.status.idle": "2024-05-30T22:46:20.782812Z",
     "shell.execute_reply": "2024-05-30T22:46:20.782812Z",
     "shell.execute_reply.started": "2024-05-30T22:46:07.036994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 92 is unsorted & has 2494 spikes\n",
      "Unit 92 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-1_t1b3L_box1_merged.rec\n",
      "<class 'numpy.ndarray'>\n",
      "Unit 103 is unsorted & has 512 spikes\n",
      "Unit 103 will be deleted\n",
      "20230622_110832_standard_comp_to_both_rewarded_D1_subj_1-2_t3b3L_box1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multirecording_spikeanalysis_edit4 as spike\n",
    "\n",
    "# It takes several steps to create the timestamp_dicts, refer to Ephys_Analysis_Notebook to create\n",
    "timestamp_dicts = pickle.load(open('timestamp_dicts.pkl', 'rb'))\n",
    "\n",
    "# Construct the path in a platform-independent way (HiPerGator or Windows)\n",
    "ephys_path = Path('.') / 'export' / 'updated_phys' / 'test'\n",
    "\n",
    "ephys_data = spike.EphysRecordingCollection(str(ephys_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344dc28c-29d4-4673-8f88-545848601c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T22:46:21.009905Z",
     "iopub.status.busy": "2024-05-30T22:46:21.009905Z",
     "iopub.status.idle": "2024-05-30T22:46:21.702323Z",
     "shell.execute_reply": "2024-05-30T22:46:21.702323Z",
     "shell.execute_reply.started": "2024-05-30T22:46:21.009905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "for recording in ephys_data.collection.keys():\n",
    "    # Check if the recording key (without everything after subject #) is in timestamp_dicts\n",
    "    start_pos = recording.find('subj_')\n",
    "    # Add the length of 'subj_' and 3 additional characters to include after 'subj_'\n",
    "    end_pos = start_pos + len('subj_') + 3\n",
    "    # Slice the recording key to get everything up to and including the subject identifier plus three characters\n",
    "    recording_key_without_suffix = recording[:end_pos]\n",
    "    if recording_key_without_suffix in timestamp_dicts:\n",
    "        # Assign the corresponding timestamp_dicts dictionary to event_dict\n",
    "        ephys_data.collection[recording].event_dict = timestamp_dicts[recording_key_without_suffix]\n",
    "        \n",
    "        # Extract the subject from the recording key\n",
    "        start = recording.find('subj_') + 5  # Start index after 'subj_'\n",
    "        subject = recording[start:start+3]\n",
    "        \n",
    "        # Assign the extracted subject\n",
    "        ephys_data.collection[recording].subject = subject\n",
    "        \n",
    "spike_analysis = spike.SpikeAnalysis_MultiRecording(ephys_data, timebin = 100, ignore_freq = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d04d5-b995-4463-9c00-356828d12334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
